# -*- coding: utf-8 -*-
"""train_detectron2_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zN_tDLMulvE7RI1x-8nejyqfkOoTt1dX

# INSTALLING THE REQUIRED LIBRARIES AND SUPPORT

THERE ARE MULTIPLE WAYS TO SETUP DETECTRON2. YOU CAN EXPLORE OTHER OPTIONS AS WELL, WHICHEVER WAY WORKS THE BEST FOR YOU.
"""

!python -m pip install pyyaml==5.1
!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

!pip install labelme
!pip install labelme2coco
!pip install rarfile

from google.colab import drive
drive.mount('/content/drive')

"""# EXTRACTING THE DATA TO OUR WORKING ENVIRONMENT IN COLAB."""

from rarfile import RarFile
import os

# Specify the path to the RAR file
rar_file_path = '/content/drive/MyDrive/face_project.rar' # '/replace/with/your/data.rar'

# Specify the extraction path
extracted_path = '/content/'  # 'replace/with/desired/output/path'

# Create the extraction directory if it doesn't exist
os.makedirs(extracted_path, exist_ok=True)

# Extract the contents of the RAR file
with RarFile(rar_file_path, 'r') as rar:
    rar.extractall(extracted_path)

# List the contents of the extraction directory
extracted_contents = os.listdir(extracted_path)
extracted_contents

import torch
import detectron2
!nvcc --version
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
print("detectron2:", detectron2.__version__)

from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import matplotlib.pyplot as plt

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.datasets import register_coco_instances

# Set GPU memory limit
torch.cuda.set_per_process_memory_fraction(0.5)

"""OUR IMAGE DATASET HAVE TWO CLASSES ['MASK', 'NO MASK']. IT'S IMPORTANT TO MENTION THE CORRECT CLASSES NAMES AND NUMBER SO THAT OUR MODEL COULD TRAIN SMOOTHLY TO ACHIEVE THE DESIRED RESULTS."""

classes = ['Mask', 'No Mask']

"""# REGISTERING OUR DATA ['TRAIN', 'TEST' AND 'VALID'] WITH DETECTRON2.
NOTE- *IT'S AN IMPORTANT STEP IN MODEL TRAINING USING DETECTRON2.*
"""

# Train dataset
register_coco_instances("train_dataset_name", {}, "/path/to/train.json", "/path/to/train_images")
MetadataCatalog.get("train_dataset_name").set(thing_classes=classes)
train_metadata = MetadataCatalog.get('train_dataset_name')

# Test dataset
register_coco_instances("test_dataset_name", {}, "/path/to/test.json", "/path/to/test_images")
MetadataCatalog.get("test_dataset_name").set(thing_classes=classes)
test_metadata = MetadataCatalog.get('test_dataset_name')

# Validation dataset
register_coco_instances("valid_dataset_name", {}, "/path/to/valid.json", "/path/to/valid_images")
MetadataCatalog.get("valid_dataset_name").set(thing_classes=classes)
valid_metadata = MetadataCatalog.get('valid_dataset_name')

"""# SOME VISUALIZATIONS OF OUR TRAINING DATA AND WHAT OUR MODEL IS GOING TO PERFORM."""

import random
from detectron2.utils.visualizer import Visualizer

dataset_dicts = DatasetCatalog.get('train_dataset_name')
for d in random.sample(dataset_dicts, 5):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata)
    vis = visualizer.draw_dataset_dict(d)
    plt.figure(figsize = (14, 10))
    plt.imshow(cv2.cvtColor(vis.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))
    plt.show()

"""# CONFIGURING OUR MODEL FOR *INSTANCE SEGMENTATION* TASK."""

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("path/to/your/model_config.yaml")) # example: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("path/to/your/model_config.yaml")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6
cfg.DATASETS.TRAIN = ("train_dataset_name",)
cfg.DATASETS.TEST = ("test_dataset_name",)

cfg.SOLVER.MAX_ITER = 1000
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.IMS_PER_BATCH = 2  # Adjust this value based on available GPU memory

torch.cuda.empty_cache()

"""#TRAINING"""

from detectron2.engine import DefaultTrainer

trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

"""#MODEL PREDICTIONS ON TEST DATA."""

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model, Can change for tuning the model's performance
cfg.DATASETS.TEST = ("test_dataset_name", )
predictor = DefaultPredictor(cfg)

from detectron2.utils.visualizer import ColorMode
import glob
from google.colab.patches import cv2_imshow

# Provide a specific file pattern (e.g., '*.jpg') to match only image files
for imageName in glob.glob('/path/to/test_images/*.jpg'):
    im = cv2.imread(imageName)
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=train_metadata,
                   scale=0.8
                  )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

"""# RUN THE BELOW CELL TO DOWNLOAD THE MODEL CHECKPOINT FILE."""

from google.colab import files

files.download('/path/to/output_directory/model_final.pth')

"""# MODEL EVALUATION"""

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

evaluator = COCOEvaluator("test_dataset_name", cfg, False, output_dir="/path/to/output_directory/")
val_loader = build_detection_test_loader(cfg, "test_dataset_name")
inference_on_dataset(trainer.model, val_loader, evaluator)

#print(results)

"""# WITH MODEL FINE TUNING BETTER RESULTS CAN BE OBTAINED, ADDITIONALLY IT ALSO DEPENDS ON THE CHOICE OF YOUR MODEL YOU SELECT.

THE BELOW CELL IS JUST FOR TESTING PURPOSE, RUN ONLY IF NEEDED.
"""

# import torch
# from PIL import Image
# from detectron2.config import get_cfg
# from detectron2.modeling import build_model
# from detectron2.structures import Instances
# from detectron2 import model_zoo
# from detectron2.utils.visualizer import Visualizer
# from detectron2.data import DatasetCatalog, MetadataCatalog
# import matplotlib.pyplot as plt
# import cv2
# import os
# import numpy as np

# # Load the model configuration
# cfg = get_cfg()
# cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml"))
# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml")
# #cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
# # cfg.DATASETS.TRAIN = ("train_dataset",)
# cfg.SOLVER.MAX_ITER = 1000
# cfg.SOLVER.BASE_LR = 0.001
# cfg.SOLVER.IMS_PER_BATCH = 2  # Adjust this value based on available GPU memory
# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
# #cfg.DATASETS.TEST = ("test_dataset", )
# #predictor = DefaultPredictor(cfg)
# # Load model configuration (modify as needed)
# #cfg.merge_from_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml")
# #model.load_state_dict(torch.load("/content/drive/MyDrive/facemask_project/detectron2_maskdetectionv2.pth", map_location=torch.device("cpu")))
# cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/facemask_project/model_final.pth"
# model = build_model(cfg)
# model.eval()

# image_path = "/content/drive/MyDrive/facemask_project/images293.jpg"  # Replace with the path to your input image
# img = Image.open(image_path)
# img_array = np.array(img)

# inputs = {"image": torch.as_tensor(img_array, dtype=torch.float32).permute(2, 0, 1), "height": img_array.shape[0], "width": img_array.shape[1]}

# # Perform inference
# with torch.no_grad():
#     predictions = model([inputs])

# # Post-process the predictions
# instances = predictions[0]["instances"].to("cpu")
# boxes = instances.pred_boxes.tensor.numpy()
# scores = instances.scores.numpy()
# classes = instances.pred_classes.numpy()

# # Print or use the results as needed
# print("Predicted Boxes:", boxes)
# print("Predicted Scores:", scores)
# print("Predicted Classes:", classes)


# img_array = np.array(img)


# v = Visualizer(img_array[:, :, ::-1],MetadataCatalog.get(cfg.DATASETS.TRAIN[0]),scale=0.8)
# out = v.draw_instance_predictions(predictions[0]["instances"].to("cpu"))
# plt.imshow(out.get_image()[:, :, ::-1])